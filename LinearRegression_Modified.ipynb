{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b11237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "class LinearRegression(object):\n",
    "    \n",
    "    #in this class, we add cross validation as well for some spicy code....\n",
    "    kfold = KFold(n_splits=3)\n",
    "            \n",
    "    def __init__(self, regularization, lr=0.001, method='batch', num_epochs=500, batch_size=50, cv=kfold, init_method='zeros'):\n",
    "        self.lr         = lr\n",
    "        self.num_epochs = num_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.method     = method\n",
    "        self.cv         = cv\n",
    "        self.regularization = regularization\n",
    "        self.init_method = init_method\n",
    "\n",
    "    def mse(self, ytrue, ypred):\n",
    "        return ((ypred - ytrue) ** 2).sum() / ytrue.shape[0]\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "            \n",
    "        #create a list of kfold scores\n",
    "        self.kfold_scores = list()\n",
    "        \n",
    "        #reset val loss\n",
    "        self.val_loss_old = np.infty\n",
    "\n",
    "        #kfold.split in the sklearn.....\n",
    "        #5 splits\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.cv.split(X_train)):\n",
    "            \n",
    "            X_cross_train = X_train[train_idx]\n",
    "            y_cross_train = y_train[train_idx]\n",
    "            X_cross_val   = X_train[val_idx]\n",
    "            y_cross_val   = y_train[val_idx]\n",
    "            \n",
    "            #self.theta = np.zeros(X_cross_train.shape[1])\n",
    "            \n",
    "             # Initialize theta based on the chosen method\n",
    "            if self.init_method == 'zeros':\n",
    "                self.theta = np.zeros(X_cross_train.shape[1])\n",
    "            elif self.init_method == 'xavier':\n",
    "                variance = 2.0 / (X_cross_train.shape[1] + 1) # +1 for bias term\n",
    "                self.theta = np.random.randn(X_cross_train.shape[1]) * np.sqrt(variance)\n",
    "            else:\n",
    "                raise ValueError(\"Unknown init_method: {}\".format(self.init_method))\n",
    "            \n",
    "            #define X_cross_train as only a subset of the data\n",
    "            #how big is this subset?  => mini-batch size ==> 50\n",
    "            \n",
    "            #one epoch will exhaust the WHOLE training set\n",
    "            with mlflow.start_run(run_name=f\"Fold-{fold}\", nested=True):\n",
    "                \n",
    "                params = {\"method\": self.method, \"lr\": self.lr, \"reg\": type(self).__name__}\n",
    "                mlflow.log_params(params=params)\n",
    "                \n",
    "                for epoch in range(self.num_epochs):\n",
    "                \n",
    "                    #with replacement or no replacement\n",
    "                    #with replacement means just randomize\n",
    "                    #with no replacement means 0:50, 51:100, 101:150, ......300:323\n",
    "                    #shuffle your index\n",
    "                    perm = np.random.permutation(X_cross_train.shape[0])\n",
    "                            \n",
    "                    X_cross_train = X_cross_train[perm]\n",
    "                    y_cross_train = y_cross_train[perm]\n",
    "                    \n",
    "                    if self.method == 'sto':\n",
    "                        for batch_idx in range(X_cross_train.shape[0]):\n",
    "                            X_method_train = X_cross_train[batch_idx].reshape(1, -1) #(11,) ==> (1, 11) ==> (m, n)\n",
    "                            y_method_train = y_cross_train[batch_idx] \n",
    "                            train_loss = self._train(X_method_train, y_method_train)\n",
    "                    elif self.method == 'mini':\n",
    "                        for batch_idx in range(0, X_cross_train.shape[0], self.batch_size):\n",
    "                            #batch_idx = 0, 50, 100, 150\n",
    "                            X_method_train = X_cross_train[batch_idx:batch_idx+self.batch_size, :]\n",
    "                            y_method_train = y_cross_train[batch_idx:batch_idx+self.batch_size]\n",
    "                            train_loss = self._train(X_method_train, y_method_train)\n",
    "                    else:\n",
    "                        X_method_train = X_cross_train\n",
    "                        y_method_train = y_cross_train\n",
    "                        train_loss = self._train(X_method_train, y_method_train)\n",
    "\n",
    "                    mlflow.log_metric(key=\"train_loss\", value=train_loss, step=epoch)\n",
    "\n",
    "                    yhat_val = self.predict(X_cross_val)\n",
    "                    val_loss_new = self.mse(y_cross_val, yhat_val)\n",
    "                    mlflow.log_metric(key=\"val_loss\", value=val_loss_new, step=epoch)\n",
    "                    \n",
    "                    #record dataset\n",
    "                    mlflow_train_data = mlflow.data.from_numpy(features=X_method_train, targets=y_method_train)\n",
    "                    mlflow.log_input(mlflow_train_data, context=\"training\")\n",
    "                    \n",
    "                    mlflow_val_data = mlflow.data.from_numpy(features=X_cross_val, targets=y_cross_val)\n",
    "                    mlflow.log_input(mlflow_val_data, context=\"validation\")\n",
    "                    \n",
    "                    #early stopping\n",
    "                    if np.allclose(val_loss_new, self.val_loss_old):\n",
    "                        break\n",
    "                    self.val_loss_old = val_loss_new\n",
    "            \n",
    "                self.kfold_scores.append(val_loss_new)\n",
    "                print(f\"Fold {fold}: {val_loss_new}\")\n",
    "            \n",
    "    def _r2(self, y_true, y_pred):\n",
    "        ss_res = ((y_true - y_pred) ** 2).sum()\n",
    "        ss_tot = ((y_true - y_true.mean()) ** 2).sum()\n",
    "        r2_score = 1 - (ss_res/ss_tot)\n",
    "        return r2_score\n",
    "        \n",
    "    def _train(self, X, y):\n",
    "        yhat = self.predict(X)\n",
    "        m    = X.shape[0]        \n",
    "        grad = (1/m) * X.T @(yhat - y) + self.regularization.derivation(self.theta)\n",
    "        self.theta = self.theta - self.lr * grad\n",
    "        return self.mse(y, yhat)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return X @ self.theta  #===>(m, n) @ (n, )\n",
    "    \n",
    "    def _coef(self):\n",
    "        return self.theta[1:]  #remind that theta is (w0, w1, w2, w3, w4.....wn)\n",
    "                               #w0 is the bias or the intercept\n",
    "                               #w1....wn are the weights / coefficients / theta\n",
    "    def _bias(self):\n",
    "        return self.theta[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf64c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LassoPenalty:\n",
    "    \n",
    "    def __init__(self, l):\n",
    "        self.l = l # lambda value\n",
    "        \n",
    "    def __call__(self, theta): #__call__ allows us to call class as method\n",
    "        return self.l * np.sum(np.abs(theta))\n",
    "        \n",
    "    def derivation(self, theta):\n",
    "        return self.l * np.sign(theta)\n",
    "    \n",
    "class RidgePenalty:\n",
    "    \n",
    "    def __init__(self, l):\n",
    "        self.l = l\n",
    "        \n",
    "    def __call__(self, theta): #__call__ allows us to call class as method\n",
    "        return self.l * np.sum(np.square(theta))\n",
    "        \n",
    "    def derivation(self, theta):\n",
    "        return self.l * 2 * theta\n",
    "    \n",
    "class ElasticPenalty:\n",
    "    \n",
    "    def __init__(self, l = 0.1, l_ratio = 0.5):\n",
    "        self.l = l \n",
    "        self.l_ratio = l_ratio\n",
    "\n",
    "    def __call__(self, theta):  #__call__ allows us to call class as method\n",
    "        l1_contribution = self.l_ratio * self.l * np.sum(np.abs(theta))\n",
    "        l2_contribution = (1 - self.l_ratio) * self.l * 0.5 * np.sum(np.square(theta))\n",
    "        return (l1_contribution + l2_contribution)\n",
    "\n",
    "    def derivation(self, theta):\n",
    "        l1_derivation = self.l * self.l_ratio * np.sign(theta)\n",
    "        l2_derivation = self.l * (1 - self.l_ratio) * theta\n",
    "        return (l1_derivation + l2_derivation)\n",
    "    \n",
    "class Lasso(LinearRegression):\n",
    "    \n",
    "    def __init__(self, method, lr, l):\n",
    "        self.regularization = LassoPenalty(l)\n",
    "        super().__init__(self.regularization, lr, method)\n",
    "        \n",
    "class Ridge(LinearRegression):\n",
    "    \n",
    "    def __init__(self, method, lr, l):\n",
    "        self.regularization = RidgePenalty(l)\n",
    "        super().__init__(self.regularization, lr, method)\n",
    "        \n",
    "class ElasticNet(LinearRegression):\n",
    "    \n",
    "    def __init__(self, method, lr, l, l_ratio=0.5):\n",
    "        self.regularization = ElasticPenalty(l, l_ratio)\n",
    "        super().__init__(self.regularization, lr, method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f935c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function for looping classnames\n",
    "import sys\n",
    "\n",
    "def str_to_class(classname):\n",
    "    return getattr(sys.modules[__name__], classname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb5f66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regs = [\"Ridge\", \"Lasso\", \"ElasticNet\"]\n",
    "\n",
    "for reg in regs:\n",
    "\n",
    "    params = {\"method\": \"batch\", \"lr\": 0.1, \"l\": 0.1}\n",
    "    mlflow.start_run(run_name=f\"method-{params['method']}-lr-{params['lr']}-reg-{reg}\", nested=True)\n",
    "    \n",
    "    print(\"=\"*5, reg, \"=\"*5)\n",
    "\n",
    "    # #######\n",
    "    type_of_regression = str_to_class(reg)    #Ridge, Lasso, ElasticNet\n",
    "    model = type_of_regression(**params)  \n",
    "    model.fit(X_train, y_train)\n",
    "    yhat = model.predict(X_test)\n",
    "    mse  = model.mse(yhat, y_test)\n",
    "\n",
    "    print(\"Test MSE: \", mse)\n",
    "    mlflow.log_metric(key=\"test_mse\", value=mse)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(X_train, model.predict(X_train))\n",
    "    mlflow.sklearn.log_model(model, artifact_path='model', signature=signature)\n",
    "\n",
    "    # #######\n",
    "\n",
    "    mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
